











import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import statsmodels.api as sm

from sklearn.metrics import mean_squared_error, mean_absolute_error


# --- File paths 
DATA_DIR = "data/"

hf_file    = DATA_DIR + "hf_index.csv"          # hedge-fund-like ETF/index
fama_file  = DATA_DIR + "fama_french.csv"       # equity style factors + RF
style_file = DATA_DIR + "style_premia.csv"      # credit, term, trend proxies

# --- Load target series (HF_INDEX) ---
hf = (
    pd.read_csv(hf_file, parse_dates=["Date"])
      .set_index("Date")
      .sort_index()
)

# Expecting a column with monthly total returns, e.g. "HF_RET"
hf = hf.rename(columns={"HF_RET": "HF_RET"})

# --- Load equity style factors (Fama–French style) ---
fama = (
    pd.read_csv(fama_file, parse_dates=["Date"])
      .set_index("Date")
      .sort_index()
)

# --- Load style premia (Fung-inspired proxies) ---
style = (
    pd.read_csv(style_file, parse_dates=["Date"])
      .set_index("Date")
      .sort_index()
)

# --- Merge everything on common dates ---
data = (
    hf.join(fama, how="inner")
      .join(style, how="inner")
)

# convert percentage returns to decimals 
# Adjust the list of columns
pct_cols = ["HF_RET", "MKT_RF", "SMB", "HML", "MOM", "RF",
            "CREDIT", "TERM", "TREND_BOND", "TREND_FX", "TREND_CMDTY"]

for col in pct_cols:
    if col in data.columns:
        data[col] = data[col] / 100.0

# --- Compute hedge fund excess returns over the risk-free rate ---
data["HF_EXCESS"] = data["HF_RET"] - data["RF"]

# Quick sanity check
data.head()








from sklearn.metrics import mean_squared_error, mean_absolute_error
import numpy as np
import statsmodels.api as sm

def run_factor_regression(y, X, add_constant=True):
    """
    Run an OLS factor regression and return:
    - fitted model (statsmodels object)
    - residuals as a pandas Series
    - diagnostics dict with R2, RMSE, MAE
    """

    # Align indices 
    df = pd.concat([y, X], axis=1).dropna()

    y_aligned = df.iloc[:, 0]
    X_aligned = df.iloc[:, 1:]

    if add_constant:
        X_aligned = sm.add_constant(X_aligned)

    model = sm.OLS(y_aligned, X_aligned)
    results = model.fit()

    # Fitted values and residuals
    y_hat = results.fittedvalues
    residuals = y_aligned - y_hat

    # Diagnostics
    r2 = results.rsquared
    rmse = np.sqrt(mean_squared_error(y_aligned, y_hat))
    mae = mean_absolute_error(y_aligned, y_hat)

    metrics = {
        "R2": r2,
        "RMSE": rmse,
        "MAE": mae
    }

    return results, residuals, metrics





# Dependent variable: hedge fund excess returns
y_capm = data["HF_EXCESS"]

# Single market factor
X_capm = data[["MKT_RF"]]

capm_results, capm_residuals, capm_metrics = run_factor_regression(y_capm, X_capm)

capm_results.summary()








import matplotlib.pyplot as plt

def cumulative_return(series):
    """Convert a return series into a cumulative return index."""
    return (1 + series).cumprod() - 1

# Cumulative total return for HF_INDEX and for the equity market proxy
cum_hf  = cumulative_return(data["HF_RET"])
cum_mkt = cumulative_return(data["MKT_RF"] + data["RF"])  # market = RF + MKT_RF

cum_df = pd.DataFrame({
    "HF_INDEX": cum_hf,
    "EQUITY_MARKET": cum_mkt
})

plt.figure(figsize=(10, 5))
(cum_df * 100).plot(ax=plt.gca())
plt.title("Cumulative Total Return – HF_INDEX vs Equity Market")
plt.ylabel("Cumulative return (%)")
plt.xlabel("Date")
plt.grid(True, alpha=0.3)
plt.tight_layout()
plt.show()


plt.figure(figsize=(10, 4))
capm_residuals.plot()
plt.title("CAPM Residuals – HF_EXCESS minus fitted CAPM return")
plt.xlabel("Date")
plt.ylabel("Residual")
plt.axhline(0.0, color="black", linewidth=1)
plt.grid(True, alpha=0.3)
plt.tight_layout()
plt.show()








# Dependent variable: same as CAPM
y_ext = data["HF_EXCESS"]

# Extended factor set: market + style premia proxies
X_ext = data[["MKT_RF", "CREDIT", "TERM", "TREND_BOND", "TREND_FX", "TREND_CMDTY"]]

ext_results, ext_residuals, ext_metrics = run_factor_regression(y_ext, X_ext)

ext_results.summary()


metrics_df = pd.DataFrame({
    "CAPM": capm_metrics,
    "Style_premia_model": ext_metrics
})
metrics_df.T








from sklearn.decomposition import PCA
from sklearn.preprocessing import StandardScaler

# Select the factors used in the extended model
pca_factors = data[["MKT_RF", "CREDIT", "TERM",
                    "TREND_BOND", "TREND_FX", "TREND_CMDTY"]].dropna()

# Standardise to zero mean / unit variance
scaler = StandardScaler()
X_std = scaler.fit_transform(pca_factors)

# Run PCA
pca = PCA()
X_pca = pca.fit_transform(X_std)

# Explained variance
expl_var = pca.explained_variance_ratio_

pca_ev_df = pd.DataFrame({
    "PC": [f"PC{i+1}" for i in range(len(expl_var))],
    "Explained_Variance_Ratio": expl_var
})
pca_ev_df


plt.figure(figsize=(6, 4))
plt.bar(pca_ev_df["PC"], pca_ev_df["Explained_Variance_Ratio"])
plt.title("PCA – Explained Variance Ratio by Component")
plt.ylabel("Explained variance ratio")
plt.grid(True, alpha=0.3)
plt.tight_layout()
plt.show()


loadings = pd.DataFrame(
    pca.components_.T,
    index=pca_factors.columns,
    columns=[f"PC{i+1}" for i in range(pca.components_.shape[0])]
)
loadings








# first 4 principal components as regressors
k = 4
pc_cols = [f"PC{i+1}" for i in range(k)]

pc_df = pd.DataFrame(
    X_pca[:, :k],
    index=pca_factors.index,
    columns=pc_cols
)

# Align HF_EXCESS with the PC index
y_pc = data.loc[pc_df.index, "HF_EXCESS"]
X_pc = pc_df

pc_results, pc_residuals, pc_metrics = run_factor_regression(y_pc, X_pc)

pc_results.summary()


# --- Metric Tables
metrics_all = pd.DataFrame({
    "CAPM": capm_metrics,
    "Style_premia_model": ext_metrics,
    "PC1_to_PC4_model": pc_metrics
})

# Models
metrics_plot = metrics_all.T.loc[
    ["CAPM", "Style_premia_model", "PC1_to_PC4_model"]
].copy()


metrics_plot.index = ["CAPM", "Style", "PCs (PC1–PC4)"]

# RMSE/MAE 
rmse_scaled = metrics_plot["RMSE"] * 1e5
mae_scaled  = metrics_plot["MAE"] * 1e5

fig, axes = plt.subplots(1, 3, figsize=(11, 3))

# --- R² ---
axes[0].bar(metrics_plot.index, metrics_plot["R2"])
axes[0].set_title("R² by Model")
axes[0].set_ylabel("R²")
axes[0].set_ylim(0.68, 0.77)
axes[0].grid(True, axis="y", alpha=0.3)

# --- RMSE ---
axes[1].bar(metrics_plot.index, rmse_scaled)
axes[1].set_title("RMSE (×10⁻⁵, lower is better)")
axes[1].set_ylabel("RMSE × 10⁻⁵")
axes[1].grid(True, axis="y", alpha=0.3)

# --- MAE ---
axes[2].bar(metrics_plot.index, mae_scaled)
axes[2].set_title("MAE (×10⁻⁵, lower is better)")
axes[2].set_ylabel("MAE × 10⁻⁵")
axes[2].grid(True, axis="y", alpha=0.3)

for ax in axes:
    ax.tick_params(axis="x")  # rótulos na horizontal

plt.tight_layout()
plt.show()


from statsmodels.stats.stattools import jarque_bera

def residual_diagnostics(residuals):
    jb_stat, jb_pvalue, _, _ = jarque_bera(residuals)
    return pd.Series({
        "Skew": residuals.skew(),
        "Kurtosis": residuals.kurtosis(),
        "JB_stat": jb_stat,
        "JB_pvalue": jb_pvalue
    })

diag_capm  = residual_diagnostics(capm_residuals)
diag_style = residual_diagnostics(ext_residuals)
diag_pcs   = residual_diagnostics(pc_residuals)

diag_df = pd.DataFrame({
    "CAPM": diag_capm,
    "Style_premia_model": diag_style,
    "PC1_to_PC4_model": diag_pcs
}).T

diag_df
import matplotlib.pyplot as plt

# ensure order
order = ["CAPM", "Style_premia_model", "PC1_to_PC4_model"]

diag_plot = diag_df.loc[order].copy()
diag_plot.index = ["CAPM", "Style", "PCs (PC1–PC4)"]

fig, axes = plt.subplots(1, 2, figsize=(9, 3))

# --- Kurtosis (Fisher) ---
axes[0].bar(diag_plot.index, diag_plot["Kurtosis"])
axes[0].axhline(0.0, linestyle="--", linewidth=1)  
axes[0].set_title("Residual Kurtosis (Fisher)")
axes[0].set_ylabel("Kurtosis (Normal = 0)")
axes[0].grid(True, axis="y", alpha=0.3)

# --- Jarque–Bera ---
axes[1].bar(diag_plot.index, diag_plot["JB_stat"])
axes[1].set_yscale("log")
axes[1].set_title("Jarque–Bera Statistic (log scale)")
axes[1].set_ylabel("JB statistic (log)")
axes[1].grid(True, axis="y", alpha=0.3)

for ax in axes:
    ax.tick_params(axis="x") 

plt.tight_layout()
plt.show()








import yfinance as yf
import numpy as np
import pandas as pd

# ---------------------------------------------------------------
#  Download VIX and build volatility factor
# ---------------------------------------------------------------

# Use the earliest date in the PC dataframe as start
start_date = pc_df.index.min()

vix_raw = yf.download(
    "^VIX",
    start=start_date,     
    interval="1d",
    auto_adjust=True,
    progress=False,
)

# Choose the correct price column 
if "Adj Close" in vix_raw.columns:
    price_series = vix_raw["Adj Close"]
else:
    price_series = vix_raw["Close"]

# 1D Series of floats
price_series = price_series.astype(float)

# Resample to monthly frequency 
vix_m = price_series.resample("MS").first()


# 2. Build monthly VIX factor (standardized)

# Convert monthly prices to simple returns
vix_ret = vix_m.pct_change().dropna()

# Standardize to mean 0 / std 1
vix_factor = (vix_ret - vix_ret.mean()) / vix_ret.std()
vix_factor.name = "VIX_Factor"

# Quick check
print("VIX factor preview:")
print(vix_factor.head())
print("\nShape:", vix_factor.shape)


import statsmodels.api as sm

# 1) Columns for the first 4 principal components
pc_cols = ["PC1", "PC2", "PC3", "PC4"]

# 2) Align PCs with the VIX factor dates
pc_for_vix = pc_df.loc[vix_factor.index, pc_cols]

# 3) Build the full X: PC1–PC4 + VIX factor
X_vix = pd.concat([pc_for_vix, vix_factor], axis=1).dropna()

# 4) Align the target HF_EXCESS with X_vix
y_vix = data.loc[X_vix.index, "HF_EXCESS"]

# 5) Add constant (alpha) for statsmodels
X_vix_const = sm.add_constant(X_vix)

# 6) Run the regression
vix_model = sm.OLS(y_vix, X_vix_const).fit()

print("=== PCs + VIX regression ===")
print(vix_model.summary())





import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np

# --- 1. Input Data Structure ---
# NOTE: The RMSE and MAE values are scaled by 1e5 for better visualization labels.
data = {
    'R2': [0.706540, 0.745363, 0.737620, 0.743031],
    'RMSE': [0.000084, 0.000078, 0.000079, 0.000078],
    'MAE': [0.000062, 0.000055, 0.000057, 0.000057],
    'Model': ['CAPM', 'Equity + Style premia', 'Latent factors (PC1-PC4)', 'PCs + Volatility (VIX)']
}
metrics_df = pd.DataFrame(data).set_index('Model')

# Scaling RMSE and MAE to 1e-5 base points
metrics_df['RMSE_scaled'] = metrics_df['RMSE'] * 1e5
metrics_df['MAE_scaled'] = metrics_df['MAE'] * 1e5

# Reorder models from simplest (bottom) to most complex (top)
order = ['CAPM', 'Equity + Style premia', 'Latent factors (PC1-PC4)', 'PCs + Volatility (VIX)']
metrics_df = metrics_df.reindex(order)

# --- 2. Plotting Configuration
sns.set_style("whitegrid")

colors = ['#1f77b4', '#ff7f0e', '#2ca02c'] 

# Set global font size higher to affect all labels
plt.rcParams.update({'font.size': 20}) 
# Massive figure size to ensure clarity
fig, axes = plt.subplots(1, 3, figsize=(30, 12)) 
plt.suptitle('Model Fit Comparison - Decomposing Hedge Fund Returns', fontsize=30, fontweight='bold', y=1.02)

# List of metrics to plot
metrics_list = [('R2', axes[0], 'R-Squared', colors[0], '{:.3f}'), 
                ('RMSE_scaled', axes[1], 'RMSE (x1e-5) - Lower is Better', colors[1], '{:.2f}'),
                ('MAE_scaled', axes[2], 'MAE (x1e-5) - Lower is Better', colors[2], '{:.2f}')]

# --- 3. Plotting Loop ---
for i, (metric, ax, title, color, fmt) in enumerate(metrics_list):
    
    # Generate horizontal bar chart
    bars = ax.barh(metrics_df.index, metrics_df[metric], color=color, height=0.7)
    
    ax.set_title(title, fontsize=24) # Large title
    ax.set_xlabel(metric.replace('_scaled', ''), fontsize=20)
    
    # Increase tick label size 
    ax.tick_params(axis='x', labelsize=18)
    ax.set_xlim(left=0)

    # Adding value labels 
    for bar in bars:
        width = bar.get_width()
        label_text = fmt.format(width)

        ax.text(width * 1.005, 
                bar.get_y() + bar.get_height()/2, 
                label_text, 
                ha='left', 
                va='center', 
                fontsize=20, # Very large label font
                fontweight='bold')

# Y-axis labels (Model Names)
axes[0].tick_params(axis='y', labelsize=20) 
axes[1].tick_params(axis='y', left=False, labelleft=False)
axes[2].tick_params(axis='y', left=False, labelleft=False)

plt.tight_layout(rect=[0, 0, 1, 0.96])
plt.show()


# === 9.1 Model fit comparison (CAPM vs Style vs PCs vs PCs+VIX) ===

from sklearn.metrics import mean_squared_error, mean_absolute_error
import numpy as np
import pandas as pd

def model_metrics(results):
    """
    Compute R², RMSE and MAE for a given statsmodels OLS result.
    Uses the y used in that regression (results.model.endog).
    """
    # y used in that regression
    y_true = results.model.endog
    # fitted values from the model
    y_pred = results.fittedvalues

    r2_value = results.rsquared
    rmse = np.sqrt(mean_squared_error(y_true, y_pred))
    mae = mean_absolute_error(y_true, y_pred)

    return {"R2": r2_value, "RMSE": rmse, "MAE": mae}


# 1) CAPM
capm_metrics = model_metrics(capm_results)

# 2) Equity + style premia model
ext_metrics = model_metrics(ext_results)

# 3) PCs only (PC1–PC4)
pc_metrics = model_metrics(pc_model)

# 4) PCs + VIX (final model)
vix_metrics = model_metrics(vix_model)

# Build comparison table
metrics_all = pd.DataFrame(
    {
        "CAPM": capm_metrics,
        "Style_premia_model": ext_metrics,
        "PC1_to_PC4_model": pc_metrics,
        "PCs_plus_VIX_model": vix_metrics,
    }
).T

print("\n=== Model fit comparison (R², RMSE, MAE) ===")
display(metrics_all)








from sklearn.linear_model import LinearRegression
from shapash.explainer.smart_explainer import SmartExplainer
# 1) Use the same X as in the final regression (PC1–PC4 + VIX)
X_features = X_vix.copy()
feature_cols = X_features.columns.tolist()
print("Feature columns:", feature_cols)

# 2) Simple linear model for Shapash 
lin_model_shap = LinearRegression()
lin_model_shap.fit(X_features, y_vix)

# 3) labels for the plot
#    Automatically detect the VIX column name (e.g. '^VIX')
vix_colname = [c for c in feature_cols if "VIX" in c.upper()][0]

feature_labels = {
    "PC1": "Latent factor 1 (PC1)",
    "PC2": "Latent factor 2 (PC2)",
    "PC3": "Latent factor 3 (PC3)",
    "PC4": "Latent factor 4 (PC4)",
    vix_colname: "Volatility / tail-risk (VIX)",
}

# 4) Build the SmartExplainer
xpl = SmartExplainer(
    model=lin_model_shap,
    features_dict=feature_labels,
)

# 5) Shapash model internally
xpl.compile(x=X_features)

# 6) Global feature importance 
fig_imp = xpl.plot.features_importance(
    max_features=len(feature_cols)   # show all factors
)

# 7) Force horizontal bars (Plotly)
fig_imp.update_traces(orientation="h")

# 8) screenshot / LinkedIn
fig_imp.update_layout(
    title="What drives hedge-fund-like excess returns?",
    title_font=dict(size=26),
    font=dict(size=16),
    width=1100,
    height=650,
    template="plotly_white",
)

fig_imp.show()












